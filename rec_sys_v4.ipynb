{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems using Latent-Factor Models\n",
    "In this post, I describe an implementation of a [recommender system](!https://en.wikipedia.org/wiki/Recommender_system) based on latent-factor models and its application to the [MovieLens 100K Dataset](!http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html). The system is built within the Scikit-Learn framework to allow for using Scikit-Learn features such as [Pipelines](!http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [GridSearchCV](!http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "from time import time\n",
    "import requests\n",
    "import urllib\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML \n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='white', palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Download the MovieLens 100K Dataset. This a classic dataset which is often used to test the performance of recommender systems. We will use files 'movies.csv' and 'ratings.csv' from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\\n!unzip ml-latest-small.zip\\n!mv ml-latest-small/ ml-100k'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!unzip ml-latest-small.zip\n",
    "!mv ml-latest-small/ ml-100k\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId             title                                       genres\n",
      "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
      "1        2    Jumanji (1995)                   Adventure|Children|Fantasy\n",
      "   userId  itemId  rating   timestamp\n",
      "0       1      31     2.5  1260759144\n",
      "1       1    1029     3.0  1260759179\n"
     ]
    }
   ],
   "source": [
    "# Read in the data into pandas dataframes\n",
    "df_movies = pd.read_csv('ml-100k/movies.csv')\n",
    "df_ratings = pd.read_csv('ml-100k/ratings.csv')\n",
    "df_ratings.columns = ['userId', 'itemId', 'rating', 'timestamp']\n",
    "df_ratings['timestamp'] = df_ratings['timestamp'].astype(str)\n",
    "print (df_movies.head(2))\n",
    "print (df_ratings.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train (80%) and test (20%) datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's explore the distribution of the number of movies versus number of ratings. From the following histogram, we see that many movies are rated only by less than 10 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f752dc35828>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFYCAYAAABZHSXVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X9cVXWex/H35cJ9kAoqyNUof61T6gSRZLmijKOmEu5u\nampA6k5rP1AxtzWFQSYtdcUftKajQ+Nv8RcjNcWYP0jFRkdkpujBaLlTNm2rqXhREREQxLN/+PCu\nZHbRuCD3vJ6Ph4+433vPuZ8P+fB9v+ec+z0WwzAMAQAAj+fV2AUAAICGQegDAGAShD4AACZB6AMA\nYBKEPgAAJuHd2AXUl8rKSh05ckRBQUGyWq2NXQ4AAG5VU1Mjh8OhkJAQ+fr61mkbjwn9I0eO6Nln\nn23sMgAAaFAbN25Uz5496/Rajwn9oKAgSdeab9euXSNXAwCAe50+fVrPPvusM//qwmNC//oh/Xbt\n2un+++9v5GoAAGgYt3NKmwv5AAAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIf\nAACTIPQBADAJQh8AAJMg9AEAMAmPWXv/Vl7av6mxS/heb0fGNXYJAACTYaYPAIBJEPoAAJgEoQ8A\ngEkQ+gAAmAShDwCASRD6AACYBKEPAIBJEPoAAJgEoQ8AgEkQ+gAAmAShDwCASRD6AACYBKEPAIBJ\nEPoAAJgEoQ8AgEkQ+gAAmIS3O3eenZ2tlStXytvbWy+//LK6du2q6dOnq6amRkFBQVq4cKFsNpuy\ns7O1bt06eXl5afTo0Ro1apSqq6uVlJSkkydPymq1at68eWrfvr07ywUAwKO5baZ//vx5LVu2TJs2\nbVJ6err27NmjJUuWKC4uTps2bVLHjh2VlZWl8vJyLVu2TGvXrlVGRobWrVunkpISbdu2Tf7+/tq8\nebPi4+OVlpbmrlIBADAFt4V+Xl6eevfurRYtWshut2v27NnKz8/XwIEDJUn9+/dXXl6eCgsLFRoa\nKj8/P/n6+io8PFwFBQXKy8vToEGDJEkREREqKChwV6kAAJiC2w7vnzhxQpWVlYqPj1dpaakmT56s\niooK2Ww2SVJgYKAcDoeKi4sVEBDg3C4gIOCmcS8vL1ksFlVVVTm3BwAAt8et5/RLSkr061//WidP\nntS4ceNkGIbzuRt/vtHtjgMAgLpx2+H9wMBA9ejRQ97e3urQoYOaN2+u5s2bq7KyUpJUVFQku90u\nu92u4uJi53ZnzpxxjjscDklSdXW1DMNglg8AwI/gttDv27evDh06pKtXr+r8+fMqLy9XRESEdu3a\nJUnKyclRZGSkwsLCdPjwYZWWlurSpUsqKChQz5491adPH+3cuVOSlJubq169ermrVAAATMFth/fb\ntm2rIUOGaPTo0ZKklJQUhYaGKjExUZmZmQoODtawYcPk4+OjqVOnavz48bJYLJo0aZL8/PwUHR2t\ngwcPKjY2VjabTampqe4qFQAAU3DrOf2YmBjFxMTUGluzZs1Nr4uKilJUVFStsevfzQcAAPWDFfkA\nADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAw\nCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlC\nHwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIfAACTIPQBADAJQh8A\nAJMg9AEAMAlCHwAAkyD0AQAwCW937Tg/P19TpkzRAw88IEl68MEH9fzzz2v69OmqqalRUFCQFi5c\nKJvNpuzsbK1bt05eXl4aPXq0Ro0aperqaiUlJenkyZOyWq2aN2+e2rdv765yAQDweG4LfUl6/PHH\ntWTJEufjX/7yl4qLi9OTTz6pN998U1lZWRo2bJiWLVumrKws+fj4aOTIkRo0aJByc3Pl7++vtLQ0\nHThwQGlpaVq8eLE7ywUAwKM16OH9/Px8DRw4UJLUv39/5eXlqbCwUKGhofLz85Ovr6/Cw8NVUFCg\nvLw8DRo0SJIUERGhgoKChiwVAACP49aZ/rFjxxQfH68LFy4oISFBFRUVstlskqTAwEA5HA4VFxcr\nICDAuU1AQMBN415eXrJYLKqqqnJuDwAAbo/bQr9Tp05KSEjQk08+qePHj2vcuHGqqalxPm8Yxvdu\nd7vjAACgbtx2eL9t27aKjo6WxWJRhw4d1KZNG124cEGVlZWSpKKiItntdtntdhUXFzu3O3PmjHPc\n4XBIkqqrq2UYBrN8AAB+BLeFfnZ2tlatWiVJcjgcOnv2rEaMGKFdu3ZJknJychQZGamwsDAdPnxY\npaWlunTpkgoKCtSzZ0/16dNHO3fulCTl5uaqV69e7ioVAABTcNvh/QEDBujVV1/Vnj17VF1drVmz\nZql79+5KTExUZmamgoODNWzYMPn4+Gjq1KkaP368LBaLJk2aJD8/P0VHR+vgwYOKjY2VzWZTamqq\nu0oFAMAU3Bb6LVq0UHp6+k3ja9asuWksKipKUVFRtcaufzcfAADUD1bkAwDAJAh9AABMgtAHAMAk\nCH0AAEyC0AcAwCQIfQAATILQBwDAJAh9AABMgtAHAMAkCH0AAEyC0AcAwCQIfQAATILQBwDAJAh9\nAABMgtAHAMAkCH0AAEyC0AcAwCTqFPplZWWSpOLiYn388ce6evWqW4sCAAD1z2Xoz549Wzt27FBJ\nSYliYmKUkZGhWbNmNUBpAACgPrkM/c8//1yjRo3Sjh07NHz4cL311lv65ptvGqI2AABQj1yGvmEY\nkqR9+/ZpwIABkqSqqir3VgUAAOqdy9Dv3LmzoqOjdenSJXXv3l3vvfeeWrZs2RC1AQCAeuTt6gVz\n5szRF198oS5dukiSfvKTn2jBggVuLwwAANQvlzP9srIyZWdna8aMGZKkM2fO6MqVK24vDAAA1C+X\noZ+SkqJ7771Xx48fl3TtfH5iYqLbCwMAAPXLZeifO3dO48aNk4+PjyQpKipKlZWVbi8MAADUrzot\nzlNdXS2LxSLp2gI95eXlbi0KAADUP5cX8j377LMaOXKkHA6H4uPjdfjwYef5fQAA0HS4DP3o6GiF\nh4fr008/lc1m0xtvvCG73d4QtQEAgHp0y9D/6KOP1K9fP2VlZTnHLl26pD/+8Y+SpJEjR7q/OgAA\nUG9uGfp/+9vf1K9fP33yySff+zyhDwBA03LL0H/xxRclSQ8//LCGDh0qf3//BisKAADUP5dX73/2\n2WcaOnSoEhIS9OGHH6q6uroh6gIAAPXMZejPmTNHubm5GjVqlPbs2aOhQ4dq5syZDVEbAACoRy6v\n3pckb29v9erVS+Xl5aqqqtKBAwfcXRcAAKhnLmf6H3zwgSZPnqwhQ4YoLy9PMTEx2r17d512XllZ\nqSeeeELvvvuuTp06pbFjxyouLk5Tpkxx3p43OztbTz/9tEaNGqWtW7dKurYY0NSpUxUbG6sxY8Y4\nlwAGAAB3zmXo5+TkaNiwYdq9e7feeOMNPf74487V+Vz5zW9+47wN75IlSxQXF6dNmzapY8eOysrK\nUnl5uZYtW6a1a9cqIyND69atU0lJibZt2yZ/f39t3rxZ8fHxSktL+3FdAgAA16Gflpamixcvav78\n+ZozZ462bdtWpx1/9dVXOnbsmH7+859LkvLz8zVw4EBJUv/+/ZWXl6fCwkKFhobKz89Pvr6+Cg8P\nV0FBgfLy8jRo0CBJUkREhAoKCu6wPQAAcJ3L0J87d6727t2rzp07q1OnTtqxY4fmzJnjcsfz589X\nUlKS83FFRYVsNpskKTAwUA6HQ8XFxQoICHC+JiAg4KZxLy8vWSwW5+kAAABwZ1xeyPfll19qw4YN\nzsdjxoxRXFzcD27z3nvv6ZFHHlH79u2/93nDMOplHAAA1J3L0K+urtbVq1fl5XXtoEBNTY1qamp+\ncJt9+/bp+PHj2rdvn06fPi2bzaZmzZqpsrJSvr6+Kioqkt1ul91uV3FxsXO7M2fO6JFHHpHdbpfD\n4VC3bt1UXV0twzCcRwkAAMCdcRn6/fr108iRI/XYY49JunZuPjo6+ge3Wbx4sfPnpUuX6r777tOn\nn36qXbt26amnnlJOTo4iIyMVFhamlJQUlZaWymq1qqCgQMnJySorK9POnTsVGRmp3Nxc9erV60e2\nCQAAXIb+xIkTFRERocLCQlksFr3xxht6+OGHb/uNJk+erMTERGVmZio4OFjDhg2Tj4+Ppk6dqvHj\nx8tisWjSpEny8/NTdHS0Dh48qNjYWNlsNqWmpt5RcwAA4P/VaXEeX19fPfTQQzIMQ5cvX9Zf/vIX\n58zflcmTJzt/XrNmzU3PR0VFKSoqqtaY1WrVvHnz6rR/AABQNy5DPz4+Xl9++aXatm3rHLNYLNq4\ncaNbCwMAAPXLZeg7HA7t2bOnIWoBAABu5PJ7+iEhITpx4kRD1AIAANzI5Uy/e/fuioqKUps2bWS1\nWmUYhiwWC7N/AACaGJehv3LlSq1evVrt2rVriHoAAICbuAz9rl276vHHH2+IWgAAgBu5DP02bdpo\n7Nix6tGjh6xWq3N8ypQpbi0MAADUL5ehHxQUpKCgoIaoBQAAuJHL0E9ISGiIOgAAgJu5/MoeAADw\nDIQ+AAAmccvQf+ONN2r9FwAANG23PKf/pz/9Sf/xH/+hP//5zyorK7vp+QULFri1MAAAUL9uGfor\nVqxQQUGBjh49qt69ezdkTQAAwA1uGfodOnRQhw4dFB4erg4dOqikpEQWi0UtW7ZsyPoAAEA9qdNd\n9v7t3/5Nly5d0tWrV9W6dWstXLhQoaGhDVEfAACoJy5D/80339Ty5cv14IMPSpI+//xzzZ07Vxs3\nbnR7cQAAoP64/Mqel5eXM/Al6ac//Wmt5XgBAEDTUKfQz8nJUVlZmcrKyrR9+3ZCHwCAJsjl4f3X\nX39ds2fP1owZM+Tl5aWwsDC9/vrrDVEbAACoRy5Dv1OnTlq1alVD1AIAANyIZXgBADAJQh8AAJNw\nGfqff/55Q9QBAADczGXop6amNkQdAADAzVxeyBccHKyxY8cqLCxMPj4+zvEpU6a4tTAAAFC/XIb+\n/fffr/vvv78hagEAAG7kMvQTEhJ0/vx5nThxQqGhobp69aq8vLj+DwCApsZlen/wwQd65pln9Mtf\n/lKSNHv2bGVlZbm9MAAAUL9chv7q1av1/vvvq3Xr1pKkxMREZWZmur0wAABQv1yGvp+fn+655x7n\nY19f31oX9AEAgKbB5Tn91q1b6/e//70uX76szz77TNu3b1dAQEBD1AYAAOqRy5n+66+/rsOHD+vS\npUtKSUnR5cuXNWfOnIaoDQAA1COXM31/f3+99tprOnfunCQxywcAoIlyGfrbt2/X3LlzZbFYZBiG\nrFarfvWrX2nQoEENUR8AAKgnLkP/N7/5jTZv3qwOHTpIkr7++mu9/PLLLkO/oqJCSUlJOnv2rC5f\nvqyJEyeqW7dumj59umpqahQUFKSFCxfKZrMpOztb69atk5eXl0aPHq1Ro0apurpaSUlJOnnypKxW\nq+bNm6f27dvXT9cAAJiQy3P6drvdGfiS1Llz5zqFb25urkJCQrRhwwYtXrxYqampWrJkieLi4rRp\n0yZ17NhRWVlZKi8v17Jly7R27VplZGRo3bp1Kikp0bZt2+Tv76/NmzcrPj5eaWlpP65TAABM7pYz\n/by8PEnSP/zDP2j27NmKiIiQl5eX8vLy1LFjR5c7jo6Odv586tQptW3bVvn5+Xr99dclSf3799fq\n1avVuXNnhYaGys/PT5IUHh6ugoIC5eXladiwYZKkiIgIJScn33mXAADg1qG/fPnyWo+/+OIL588W\ni6XObxATE6PTp08rPT1dzz33nGw2myQpMDBQDodDxcXFtS4ODAgIuGncy8tLFotFVVVVzu0BAMDt\nuWXoZ2Rk1MsbbNmyRUePHtW0adNkGIZz/Mafb3S74wAAoG5cXsh38OBBbdq0SRcvXqwVvOvXr//B\n7Y4cOaLAwEDde++96t69u2pqatS8eXNVVlbK19dXRUVFstvtstvtKi4udm535swZPfLII7Lb7XI4\nHOrWrZuqq6tlGAazfAAAfgSXoT9r1ixNmDBB7dq1u60df/zxx/r22281Y8YMFRcXq7y8XJGRkdq1\na5eeeuop5eTkKDIyUmFhYUpJSVFpaamsVqsKCgqUnJyssrIy7dy5U5GRkcrNzVWvXr3uuEkAAFCH\n0O/UqZOGDx9+2zuOiYnRjBkzFBcXp8rKSr322msKCQlx3rAnODhYw4YNk4+Pj6ZOnarx48fLYrFo\n0qRJ8vPzU3R0tA4ePKjY2FjZbDalpqbeUYMAAOAai+HiZPnu3buVm5urHj16yNv7/z8jXL+y/m5x\n4sQJDRw4UHv27NH999/vHH9p/6ZGrOrW3o6Ma+wSAABN2K1y74e4nOmnp6frnnvuUVVVlXPMYrHc\ndaEPAAB+mMvQ9/Hxqbcr+QEAQONxuSLfgAEDdOjQIVVVVenq1avOPwAAoGlxOdNfvny5Kioqao1Z\nLBYdPXrUbUUBAID65zL0P/3004aoAwAAuJnL0C8qKtKuXbtuWpwnISHBrYUBAID65fKc/gsvvKCj\nR4+qurpaV65ccf4BAABNi8uZfqtWrTRv3ryGqAUAALiRy9AfNGiQsrOz1aNHD1mtVud4cHCwWwsD\nAAD1y2Xo/+1vf9Mf/vAHtWrVyjlmsVi0b98+d9YFAADqmcvQLyws1F/+8hfucAcAQBPn8kK+kJAQ\nXb58uSFqAQAAblSnr+wNGDBAXbp0qXVOf+PGjW4tDAAA1C+XoR8fH98QdQAAADdzGfo1NTUNUQcA\nAHCzOq29f111dbWOHTum8PBw9e7d262FAQCA+uUy9L97W92zZ88qLS3NbQUBAAD3cHn1/ncFBgbq\n73//uztqAQAAbuRypj9t2jRZLBbn41OnTsnL67Y/KwAAgEbmMvQjIiKcP1ssFrVo0UJ9+vRxa1EA\nAKD+uQz94cOHN0QdAADAzW4Z+gMGDKh1WN8wDFksFlVVVam4uFhHjx5tkAIBAED9uGXo792796ax\n3bt3Ky0tTU8//bRbiwIAAPXP5eF9Sfqf//kfzZkzRz4+Pvrtb3+r9u3bu7suAABQz34w9MvLy7Vs\n2TJ99NFHmjZtmvr169dQdQEAgHp2y+/ebdu2TSNGjFDLli31+9//nsAHAKCJu+VM/9VXX1WnTp20\nf/9+HThwwDl+/YK+9evXN0iBAACgftwy9Pfs2dOQdQAAADe7Zejfd999DVkHAABwM9bTBQDAJAh9\nAABMgtAHAMAkCH0AAEyC0AcAwCQIfQAATKJOa+/fqQULFuiTTz7RlStX9NJLLyk0NFTTp09XTU2N\ngoKCtHDhQtlsNmVnZ2vdunXy8vLS6NGjNWrUKFVXVyspKUknT56U1WrVvHnzWPMfAIAfwW2hf+jQ\nIX355ZfKzMzU+fPnNXz4cPXu3VtxcXF68skn9eabbyorK0vDhg3TsmXLlJWVJR8fH40cOVKDBg1S\nbm6u/P39lZaWpgMHDigtLU2LFy92V7kAAHg8tx3ef+yxx/TWW29Jkvz9/VVRUaH8/HwNHDhQktS/\nf3/l5eWpsLBQoaGh8vPzk6+vr8LDw1VQUKC8vDwNGjRIkhQREaGCggJ3lQoAgCm4LfStVquaNWsm\nScrKytLPfvYzVVRUyGazSZICAwPlcDhUXFysgIAA53YBAQE3jXt5eclisaiqqspd5QIA4PHcfiHf\n7t27lZWVpddee63WuGEY3/v62x0HAAB149bQ379/v9LT07VixQr5+fmpWbNmqqyslCQVFRXJbrfL\nbreruLjYuc2ZM2ec4w6HQ5JUXV0twzCcRwkAAMDtc1voX7x4UQsWLNDbb7+tVq1aSbp2bn7Xrl2S\npJycHEVGRiosLEyHDx9WaWmpLl26pIKCAvXs2VN9+vTRzp07JUm5ubnq1auXu0oFAMAU3Hb1/vbt\n23X+/Hn9+7//u3MsNTVVKSkpyszMVHBwsIYNGyYfHx9NnTpV48ePl8Vi0aRJk+Tn56fo6GgdPHhQ\nsbGxstlsSk1NdVepAACYgttC/5lnntEzzzxz0/iaNWtuGouKilJUVFStsevfzQcAAPWDFfkAADAJ\nQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIf\nAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAA\nkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMAlCHwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg\n9AEAMAlCHwAAkyD0AQAwCbeG/hdffKEnnnhCGzZskCSdOnVKY8eOVVxcnKZMmaKqqipJUnZ2tp5+\n+mmNGjVKW7dulSRVV1dr6tSpio2N1ZgxY3T8+HF3lgoAgMdzW+iXl5dr9uzZ6t27t3NsyZIliouL\n06ZNm9SxY0dlZWWpvLxcy5Yt09q1a5WRkaF169appKRE27Ztk7+/vzZv3qz4+HilpaW5q1QAAEzB\nbaFvs9m0YsUK2e1251h+fr4GDhwoSerfv7/y8vJUWFio0NBQ+fn5ydfXV+Hh4SooKFBeXp4GDRok\nSYqIiFBBQYG7SgUAwBTcFvre3t7y9fWtNVZRUSGbzSZJCgwMlMPhUHFxsQICApyvCQgIuGncy8tL\nFovFeToAAADcvka7kM8wjHoZBwAAddOgod+sWTNVVlZKkoqKimS322W321VcXOx8zZkzZ5zjDodD\n0rWL+gzDcB4lAAAAt8+7Id8sIiJCu3bt0lNPPaWcnBxFRkYqLCxMKSkpKi0tldVqVUFBgZKTk1VW\nVqadO3cqMjJSubm56tWrV0OW6nYv7d/U2CV8r7cj4xq7BACAm7gt9I8cOaL58+fr22+/lbe3t3bt\n2qVFixYpKSlJmZmZCg4O1rBhw+Tj46OpU6dq/PjxslgsmjRpkvz8/BQdHa2DBw8qNjZWNptNqamp\n7ioVAABTcFvoh4SEKCMj46bxNWvW3DQWFRWlqKioWmNWq1Xz5s1zV3kAAJgOK/IBAGAShD4AACZB\n6AMAYBKEPgAAJkHoAwBgEoQ+AAAmQegDAGAShD4AACZB6AMAYBKEPgAAJkHoAwBgEoQ+AAAmQegD\nAGAShD4AACZB6AMAYBKEPgAAJkHoAwBgEoQ+AAAmQegDAGAS3o1dAO4uL+3f1NglfK+3I+MauwQA\naPKY6QMAYBKEPgAAJkHoAwBgEoQ+AAAmQegDAGAShD4AACbBV/bQJPBVQgD48ZjpAwBgEoQ+AAAm\nQegDAGAShD4AACZB6AMAYBJcvQ/8CHyrAEBTQugDHogPIwC+D6EPoMHwYQRoXHd16P/nf/6nCgsL\nZbFYlJycrIcffrixSwLggfgwArO4a0P/z3/+s7755htlZmbqq6++UnJysjIzMxu7LABoMHwYQX27\na0M/Ly9PTzzxhCSpS5cuunDhgsrKytSiRYtGrgwAzO1u/TBiNhXFJbe9zV0b+sXFxXrooYecjwMC\nAuRwOG4Z+jU1NZKk06dP1xq/k18KAAB3u8vnSiX9f/7VxV0b+t9lGMYPPu9wOCRJzz77bEOUAwDA\nXcHhcKhjx451eu1dG/p2u13FxcXOx2fOnFFQUNAtXx8SEqKNGzcqKChIVqu1IUoEAKDR1NTUyOFw\nKCQkpM7b3LWh36dPHy1dulQxMTH67LPPZLfbf/B8vq+vr3r27NmAFQIA0LjqOsO/7q4N/fDwcD30\n0EOKiYmRxWLRzJkzG7skAACaNIvh6mQ5AADwCNxwBwAAkyD0AQAwibv2nP7t8NTler/44gtNnDhR\nv/jFLzRmzBidOnVK06dPV01NjYKCgrRw4ULZbLbGLvOOLFiwQJ988omuXLmil156SaGhoR7TW0VF\nhZKSknT27FldvnxZEydOVLdu3Tymv+sqKyv1T//0T5o4caJ69+7tMf3l5+drypQpeuCBByRJDz74\noJ5//nmP6S87O1srV66Ut7e3Xn75ZXXt2tVjetu6dauys7Odj48cOaLt27d7TH+XLl1SYmKiLly4\noOrqak2aNEk/+clPbq8/o4nLz883XnzxRcMwDOPYsWPG6NGjG7mi+nHp0iVjzJgxRkpKipGRkWEY\nhmEkJSUZ27dvNwzDMNLS0oyNGzc2Zol3LC8vz3j++ecNwzCMc+fOGf369fOY3gzDMD744APjt7/9\nrWEYhnHixAlj8ODBHtXfdW+++aYxYsQI45133vGo/g4dOmRMnjy51pin9Hfu3Dlj8ODBxsWLF42i\noiIjJSXFY3r7rvz8fGPWrFke1V9GRoaxaNEiwzAM4/Tp08aQIUNuu78mf3j/Vsv1NnU2m00rVqyQ\n3W53juXn52vgwIGSpP79+ysvL6+xyvtRHnvsMb311luSJH9/f1VUVHhMb5IUHR2tF154QZJ06tQp\ntW3b1qP6k6SvvvpKx44d089//nNJnvN381Y8pb+8vDz17t1bLVq0kN1u1+zZsz2mt+9atmyZJk6c\n6FH9tW7dWiUl11aZLS0tVevWrW+7vyYf+sXFxWrdurXz8fXleps6b29v+fr61hqrqKhwHrYJDAxs\nsn1arVY1a9ZMkpSVlaWf/exnHtPbjWJiYvTqq68qOTnZ4/qbP3++kpKSnI89rb9jx44pPj5esbGx\n+tOf/uQx/Z04cUKVlZWKj49XXFyc8vLyPKa3G/31r3/Vvffeq6CgII/qb+jQoTp58qQGDRqkMWPG\nKDEx8bb784hz+jcyTPINRE/oc/fu3crKytLq1as1ePBg57gn9CZJW7Zs0dGjRzVt2rRaPTX1/t57\n7z098sgjat++/fc+39T769SpkxISEvTkk0/q+PHjGjduXK21zZt6fyUlJfr1r3+tkydPaty4cR71\nd/O6rKwsDR8+/Kbxpt7f+++/r+DgYK1atUr//d//reTk5FrP16W/Jh/6t7tcb1PWrFkzVVZWytfX\nV0VFRbVE+Gq2AAAH9UlEQVQO/Tc1+/fvV3p6ulauXCk/Pz+P6u3IkSMKDAzUvffeq+7du6umpkbN\nmzf3mP727dun48ePa9++fTp9+rRsNptH/f9r27atoqOjJUkdOnRQmzZtdPjwYY/oLzAwUD169JC3\nt7c6dOig5s2by2q1ekRvN8rPz1dKSookz/p3s6CgQH379pUkdevWTWfOnNE999xzW/01+cP7ffr0\n0a5duySpTsv1NmURERHOXnNychQZGdnIFd2ZixcvasGCBXr77bfVqlUrSZ7TmyR9/PHHWr16taRr\np5/Ky8s9qr/FixfrnXfe0e9+9zuNGjVKEydO9Kj+srOztWrVKknXbmRy9uxZjRgxwiP669u3rw4d\nOqSrV6/q/PnzHvd3U5KKiorUvHlz5yFvT+qvY8eOKiwslCR9++23at68ea0MrEt/HrEi36JFi/Tx\nxx87l+vt1q1bY5f0ox05ckTz58/Xt99+K29vb7Vt21aLFi1SUlKSLl++rODgYM2bN08+Pj6NXept\ny8zM1NKlS9W5c2fnWGpqqlJSUpp8b9K1r7LNmDFDp06dUmVlpRISEhQSEqLExESP6O9GS5cu1X33\n3ae+fft6TH9lZWV69dVXVVpaqurqaiUkJKh79+4e09+WLVuUlZUlSZowYYJCQ0M9pjfp2r+dixcv\n1sqVKyVdO/rrKf1dunRJycnJOnv2rK5cuaIpU6aoS5cut9WfR4Q+AABwrckf3gcAAHVD6AMAYBKE\nPgAAJkHoAwBgEoQ+AAAmQegDjezEiRPq2rVrrbuDSdKAAQMarIaxY8fq4MGDbn2Pb775RoMHD9as\nWbPuaPuioiLnuuLvvvuutm7dWo/VAeZA6AN3gU6dOmnZsmUecbOoW/n000/105/+9I5DPz8/X4cO\nHZIkjRgxQqNGjarH6gBzaPLL8AKewG63q2/fvlq+fLmmT59e67l3331XBw8e1KJFiyRdm5VPmDBB\nVqtV6enpateunQ4fPqywsDB17dpVH374oUpKSrRixQq1a9dOPXr00IQJE7R3715VV1crPj5ev/vd\n7/T1119r1qxZzmU99+7dq5UrV6qoqEgTJ07U0KFDdeHCBc2cOVPnzp1TWVmZnnvuOf3zP/+zli5d\nqhMnTujkyZNKTExUSEiIs96vv/5aM2fOlGEYunLliqZOnaqgoCClp6ertLRUs2bNqhX8391XZWWl\nFi1aJJvNpsrKSs2cOVP+/v5avHixDMNQq1atVFZWpitXruiVV17Ro48+qvj4eO3fv18Oh0OLFy9W\n165d9dFHHyktLU0tW7ZUZGSkNmzYoD/+8Y/avn27Vq1apWbNmskwDM2bN++W9xEAPA0zfeAu8dxz\nz+mjjz7S3//+9zpv89e//lWJiYl655139Ic//EH+/v7KyMjQQw89pJ07d0qSysvLFRISoi1btqhZ\ns2bau3evVqxYoYkTJ2rTpk3OfdXU1Gj16tVavny55s6dq6tXr2rx4sWKjIzU+vXrtWHDBi1ZskTn\nzp2TdO20xPr162sFviTNmTNHsbGxysjI0KxZs5SYmKiOHTvqxRdfVERExPfO9G/cV0lJiWbNmqX1\n69dr3Lhxevvtt9W+fXsNHz5c//Iv/6Lnnnuu1rZlZWV68MEHtX79eg0dOlRbt26VYRiaOXOmFixY\noIyMDF28eNH5+vT0dL322mvKyMjQtGnTVFRUVOffN9DUMdMH7hI2m03Tp0/X3LlznWu/u9KlSxfn\n/QtatWqlHj16SLp205gbTxU8+uijzvHw8HBJUrt27WqFYZ8+fSRdW99bks6dO6f8/HwdPnxY7733\nnqRrt3w+ceKEJCksLEwWi+WmmgoLC/Vf//VfkqSuXbuqrKzM+UHhVm7cV5s2bbRgwQJdvnxZFy9e\nVMuWLV3+Hv7xH/9RkhQcHKxvvvnGua789SW5hwwZovfff1/StVMDSUlJGjx4sAYPHqywsDCX+wc8\nBTN94C7Sr18/+fj46MMPP3SOfTdYq6urnT9brdZaz934+MYVtm8c/+423/c+hmHIYrHIZrNp5syZ\nysjIUEZGhnbs2KGHH35Ykm65vvf3fRD4vrEb3biv6dOn64UXXtDGjRv1yiuv/OB213237+v1f9/z\nv/jFL5SRkaFOnTrptdde05YtW+r0HoAnIPSBu0xycrLS0tJUVVUlSWrRooVOnz4tSTp79qy+/PJL\nt7zv9Svjv/76a1mtVgUEBOjRRx/Vjh07JF27kdCsWbN05cqVH9xPWFiYDhw4IEn6/PPP1apVK7Vu\n3brOdRQXF+uBBx5QTU2Ndu7c6fw9WCwWl+99XevWreXl5eU8VZKTkyPp2imMRYsWyc/PT8OHD9fk\nyZOddy0DzIDD+8BdpkOHDhoyZIjS09MlXTvsvmrVKo0ePVpdunRxHsKvb97e3powYYL+93//Vykp\nKbJYLEpISFBKSopiY2NVVVWlZ555Rt7eP/zPxq9+9SvNnDlTmzdv1pUrV7RgwYLbquOFF17Qv/7r\nvyo4OFjjx4/X9OnTtXbtWvXs2VOvvPKKfHx8bnm04jovLy8lJydr0qRJCg4OVs+ePeXt7S2r1arW\nrVsrJiZG/v7+kuS87zpgBtxlD4BH2r17t7p27ar27dsrJydHmZmZdb5WAvBUzPQBeKSrV69q8uTJ\natGihWpqau54fQDAkzDTBwDAJLiQDwAAkyD0AQAwCUIfAACTIPQBADAJQh8AAJMg9AEAMIn/AyDi\nbnM9CVt7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f752dc785f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_ratings.groupby(['itemId'])['userId']\n",
    "                   .count().values, bins=50);\n",
    "plt.xlim(0,80)\n",
    "plt.xlabel('Nummber of ratings')\n",
    "plt.ylabel('Nummber of movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We partition our dataset into train and test sets by removing 10 randomly selected movies rated by each user from the original dataset and placing them in the test set. The remaining dataset is our train set. \n",
    "\n",
    "The following function can be used to partition our dataset into train and test sets. We will use it later in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93423 6710 100004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ratings_extractor = RatingsExtractor()\\nratings_extractor.transform(df_train)\\n\\nratings_extractor = RatingsExtractor()\\nratings_extractor.transform(df_ratings)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split_df(df, test_size=10):\n",
    "    def drop_rows(df, remove_n):#, itemIds_single_rating):\n",
    "        drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "        #drop_indices = [i for i in drop_indices if i not in itemIds_single_rating]\n",
    "        return df.drop(drop_indices)\n",
    "\n",
    "    # ItemIds' occuring more than 20 times\n",
    "    counts = collections.Counter(df['itemId'])\n",
    "    #itemIds_single_rating = [k for k,v in counts.items() if v<2]\n",
    "\n",
    "    grouped = df.groupby(by=['userId'], group_keys=False)\n",
    "    remove_n = test_size\n",
    "    df_train = df.groupby(['userId']).apply(\n",
    "                    lambda x: drop_rows(x, remove_n))#, \n",
    "                                        #itemIds_single_rating))\n",
    "    df_train = df_train.reset_index(level=0, drop=True)\n",
    "    df_test = df[~df.index.isin(df_train.index)]\n",
    "    \n",
    "    removed_item_ids = set(df['itemId']) - set(df_train['itemId'])\n",
    "    dummy_ratings = []\n",
    "    dummy_userIds = np.random.choice(df['userId'].unique(), \n",
    "                                 size=len(removed_item_ids))\n",
    "    for i,itemid in enumerate(removed_item_ids):\n",
    "        dummy_ratings.append([dummy_userIds[i],itemid,0.001,'NaN'])\n",
    "    \n",
    "    df_train_dummy = pd.DataFrame(dummy_ratings, columns=['userId', 'itemId', 'rating', 'timestamp'])\n",
    "    df_train = pd.concat([df_train, df_train_dummy])\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\"\"\"#df_train, df_test = train_test_split_df(df_ratings.iloc[:1000], test_size=10)\n",
    "df_train, df_test = train_test_split_df(df_ratings, test_size=10)\n",
    "print (len(df_train), len(df_test), len(df_ratings))\"\"\"\n",
    "\n",
    "\"\"\"ratings_extractor = RatingsExtractor()\n",
    "ratings_extractor.transform(df_train)\n",
    "\n",
    "ratings_extractor = RatingsExtractor()\n",
    "ratings_extractor.transform(df_ratings)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "The following transformer (called RatingsExtractor) converts a pandas dataframe containing itemIds, userIds, and ratings into an $m \\times n$ sparse matrix, where $m$ is the number of items and $n$ is the number of users. It also implements dictionaries to convert the row and column indices into item and user ids and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ratings_extractor = RatingsExtractor()\\nratings = ratings_extractor.transform(df_ratings)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RatingsExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.index2user_dict = {}\n",
    "        self.index2item_dict = {}\n",
    "        self.user2index_dict = {}\n",
    "        self.item2index_dict = {}\n",
    "        self.ratings = csr_matrix([], dtype=np.float)\n",
    "\n",
    "    def fit(self,df_ratings):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_ratings):\n",
    "        for i,uid in enumerate(sorted(df_ratings['userId'].unique())):\n",
    "            self.index2user_dict[i] = uid\n",
    "        for i,mid in enumerate(sorted(df_ratings['itemId'].unique())):\n",
    "            self.index2item_dict[i] = mid\n",
    "            \n",
    "        self.user2index_dict = {v:k for k,v in self.index2user_dict.items()}\n",
    "        self.item2index_dict = {v:k for k,v in self.index2item_dict.items()}\n",
    "\n",
    "        n_items = len(self.index2item_dict)\n",
    "        n_users = len(self.index2user_dict)\n",
    "        row_ind = [self.item2index_dict[mov]  \n",
    "                   for mov in df_ratings['itemId'].values]\n",
    "        col_ind = [self.user2index_dict[mov] \n",
    "                   for mov in df_ratings['userId'].values]\n",
    "        data = df_ratings['rating'].values\n",
    "\n",
    "        self.ratings = csr_matrix((data, (row_ind, col_ind)), shape=(n_items, n_users))\n",
    "        return self.ratings\n",
    "    \n",
    "    def get_row_col_indices(self, df_test):\n",
    "        row_indices = [self.item2index_dict[k] \n",
    "                       for k in df_test['itemId'].values]\n",
    "        col_indices = [self.user2index_dict[k] \n",
    "                       for k in df_test['userId'].values]\n",
    "        return list(zip(row_indices,col_indices))\n",
    "\n",
    "\n",
    "\"\"\"ratings_extractor = RatingsExtractor()\n",
    "ratings = ratings_extractor.transform(df_ratings)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator\n",
    "Our estimator implements the intuition shown in the figure below.\n",
    "\n",
    "![](img/rec_sys_matrices.png)\n",
    "\n",
    "\n",
    "So our predicted rating for item-user pair ($i,x$) is given by:\n",
    "\\begin{align}\n",
    "\\hat{r}_{ix} = \\mu + b_i + b_x + \\mathbf{q_i} \\cdot \\mathbf{p_x} \\\\\n",
    "\\end{align}\n",
    "\n",
    "where,\n",
    "\n",
    "$\\mu$ is the global mean rating,\n",
    "\n",
    "$b_i$ is the item bias for item $i$,\n",
    "\n",
    "$b_x$ is the user bias for user $x$,\n",
    "\n",
    "$\\mathbf{q_i}$ is the latent factor vector for item $i$, and\n",
    "\n",
    "$\\mathbf{p_x}$ is the latent factor vector for user $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function can be written as\n",
    "\\begin{align}\n",
    "J = \n",
    " \\sum_{(i,x) \\in R} \\left( r_{i,x} - \\left( \\mu + \n",
    "                      b_i + b_x + \n",
    "                      \\mathbf{q_i} \\cdot \\mathbf{p_x} \\right) \\right)^2  \n",
    "                   + \\lambda_{if} \\sum_i \\left\\lVert q_i \\right\\rVert ^2  \n",
    "                   + \\lambda_{xf} \\sum_x \\left\\lVert p_x \\right\\rVert ^2 \\\\  \n",
    "                   + \\lambda_{ib} \\sum_i b_i^2 + \n",
    "                   \\lambda_{xb} \\sum_x b_x^2 \n",
    "\\end{align}\n",
    "\n",
    "Here, $\\lambda_{if}, \\lambda_{xf}, \\lambda_{ib}, \\lambda_{xb}$ are regularization parameters. I used Stochastic Gradient Descent (SGD) algorithm to minimize the objective function $J$. Alternatively, one can also use Alternating Least Squares (ALS) algorithm.\n",
    "\n",
    "In the SGD algorithm, we update each parameter ($b_x$, $b_i$, $q_i$, and $p_x$) with each sample using gradient update of the form\n",
    "\n",
    "\\begin{align}\n",
    "\\theta := \\theta - \\eta \\frac{\\partial J}{\\partial \\theta}\n",
    "\\end{align}.\n",
    "\n",
    "Our SGD parameter updates become\n",
    "\\begin{align}\n",
    "b_i := b_i + \\eta \\left( e_{ix} - \\lambda{ib} b_i \\right) \\\\\n",
    "b_x := b_x + \\eta \\left( e_{ix} - \\lambda_{xb} b_x \\right) \\\\\n",
    "\\mathbf{q_i} := \\mathbf{q_i} + \\eta \\left( e_{ix} \\mathbf{p_x} - \\lambda_{if} \\mathbf{q_i} \\right) \\\\\n",
    "\\mathbf{p_x} := \\mathbf{p_x} + \\eta \\left( e_{ix} \\mathbf{q_i} - \\lambda_{xf} \\mathbf{p_x} \\right)\n",
    "\\end{align}\n",
    "\n",
    "where, $e_{ix} = r_{ix} - \\hat{r}_{ix}$ is the prediction error.\n",
    "\n",
    "The above algorithm is implemented in LatentFactorRecSys class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rec = LatentFactorRecSys(max_iter=2)\\n# print (rec.get_params())\\n# rec.set_params(max_iter=10)\\n\\nrec.fit(ratings)\\n\\nconv_curve = rec.get_convergence_curve()\\niter_index,rmse = tuple(zip(*conv_curve))\\n\\nplt.plot(iter_index,rmse, '-ok')\\nplt.xlabel('iteration')\\nplt.ylabel('RMSE')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LatentFactorRecSys(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, reg_item_fact=0.1, reg_user_fact=0.1, \n",
    "                 reg_item_bias=0.1, reg_user_bias=0.1,\n",
    "                 num_factors=20,\n",
    "                 learning_rate=0.001, max_iter=10,\n",
    "                 tolerance=0.1):\n",
    "        self.reg_item_fact = reg_item_fact\n",
    "        self.reg_user_fact = reg_user_fact\n",
    "        self.reg_item_bias = reg_item_bias\n",
    "        self.reg_user_bias = reg_user_bias\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        \"\"\"self.R = csr_matrix([], dtype=np.float)\n",
    "        self.mu = 0.0\n",
    "        self.bx = csr_matrix([], dtype=np.float)\n",
    "        self.bi = csr_matrix([], dtype=np.float)\n",
    "        self.P = csr_matrix([], dtype=np.float)\n",
    "        self.Q = csr_matrix([], dtype=np.float)\n",
    "        self.rmse_iter = []\"\"\"\n",
    "        \n",
    " \n",
    "    def fit(self,ratings,y=None):\n",
    "        self.R = ratings\n",
    "\n",
    "        f = self.num_factors\n",
    "        eta = self.learning_rate\n",
    "        lambda_if = self.reg_item_fact\n",
    "        lambda_xf = self.reg_user_fact\n",
    "        lambda_ib = self.reg_item_bias\n",
    "        lambda_xb = self.reg_user_bias\n",
    "            \n",
    "        #nonzero_indices = list(zip(self.R.nonzero()[0].tolist(),\n",
    "        #                           self.R.nonzero()[1].tolist()))\n",
    "        nonzero_indices = list(zip(*ratings.nonzero()))\n",
    "        n_items,n_users = self.R.shape \n",
    "        \n",
    "        self.P = np.random.uniform(0,np.sqrt(self.R.max()/f),\n",
    "                                   size=(n_users,f)) # User factors\n",
    "        self.Q = np.random.uniform(0,np.sqrt(self.R.max()/f),\n",
    "                                   size=(n_items,f)) # Item factors\n",
    "        self.bx = np.random.uniform(-1,1,n_users) # User bias\n",
    "        self.bi = np.random.uniform(-1,1,n_items) # Item bias\n",
    "        self.mu = self.R.sum()/self.R.size # Overall mean rating\n",
    "        \n",
    "        self.rmse_iter = []\n",
    "        for it in range(self.max_iter):    \n",
    "            for i,x in nonzero_indices:\n",
    "                res_ix = self.R[i,x] - self.predict_ix(i,x)\n",
    "                self.bx[x]  += eta*(res_ix - lambda_xb*self.bx[x])\n",
    "                self.bi[i]  += eta*(res_ix - lambda_ib*self.bi[i])\n",
    "                ptemp = self.P[x,:]\n",
    "                self.P[x,:] += eta*(res_ix*self.Q[i,:] - \n",
    "                                    lambda_xf*self.P[x,:])\n",
    "                self.Q[i,:] += eta*(res_ix*ptemp - \n",
    "                                    lambda_if*self.Q[i,:])        \n",
    "        \n",
    "            cur_rmse = self.rmse_all()\n",
    "            self.rmse_iter.append((it,cur_rmse))\n",
    "            if (it>0 and self.rmse_iter[it-1][1]-cur_rmse < self.tolerance):\n",
    "                print ('converged at iter = %d, rmse = %f' % (it+1, cur_rmse))\n",
    "                return self\n",
    "            \n",
    "        print ('not converged, number of iterations exceeded max_iter = %d ' % self.max_iter)\n",
    "        print ('current rmse = %f' % cur_rmse)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self,ratings,y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict_ix(self,item_index,user_index):\n",
    "        return (self.mu + self.bx[user_index] + self.bi[item_index] + \n",
    "                np.dot(self.P[user_index,:],self.Q[item_index,:]))\n",
    "    \n",
    "    def predict(self,itemid_userid_array,ratings_extractor):\n",
    "        pred = []\n",
    "        for itemid,userid in itemid_userid_array:\n",
    "            item_index = ratings_extractor.item2index_dict[itemid]\n",
    "            user_index = ratings_extractor.user2index_dict[userid]\n",
    "            #print (itemid,userid,item_index,user_index)\n",
    "            pred.append(self.predict_ix(item_index,user_index))\n",
    "        return pred\n",
    "    \n",
    "        \n",
    "    def predict_all(self):\n",
    "        n_items, n_users = self.R.shape\n",
    "\n",
    "        #nonzero_indices = list(zip(self.R.nonzero()[0].tolist(),\n",
    "        #                           self.R.nonzero()[1].tolist()))\n",
    "        nonzero_indices = list(zip(*self.R.nonzero()))\n",
    "        row_ind = [i for i,x in nonzero_indices]\n",
    "        col_ind = [x for i,x in nonzero_indices]\n",
    "        mask = csr_matrix(([1.]*self.R.size, (row_ind, col_ind)), \n",
    "                          shape=(n_items, n_users))\n",
    "        \n",
    "        biases = (self.mu*mask \n",
    "                  + mask.multiply(np.tile(self.bx,(n_items,1))) \n",
    "                  + mask.multiply(np.tile(self.bi[np.newaxis].transpose(),\n",
    "                                        (1,n_users))))\n",
    "        predictions = biases + mask.multiply(np.matmul(self.Q,self.P.T)) # elementwise multiplication\n",
    "        return predictions\n",
    "        \n",
    "        \n",
    "    def rmse_all(self):\n",
    "        Residue = self.R - self.predict_all() \n",
    "        return np.sqrt(Residue.multiply(Residue).sum()/self.R.size)\n",
    "        \n",
    "    def score(self,ratings,y=None):\n",
    "        # rec.named_steps['lf_recommender'].R.data                \n",
    "        return r2_score(self.R.data, self.predict_all().data)\n",
    "    \n",
    "    def get_convergence_curve(self):\n",
    "        return self.rmse_iter\n",
    "    \n",
    "    \n",
    "\"\"\"rec = LatentFactorRecSys(max_iter=2)\n",
    "# print (rec.get_params())\n",
    "# rec.set_params(max_iter=10)\n",
    "\n",
    "rec.fit(ratings)\n",
    "\n",
    "conv_curve = rec.get_convergence_curve()\n",
    "iter_index,rmse = tuple(zip(*conv_curve))\n",
    "\n",
    "plt.plot(iter_index,rmse, '-ok')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('RMSE')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "We combine our RatingsExtractor and LatentFactorRecSys classes in a scikit-learn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"num_samples = 1000\\nrec_pipeline.fit(df_ratings.sample(num_samples, random_state=0))\\nprint (rec_pipeline)\\n\\nconv_curve = rec_pipeline.named_steps['lf_recommender'].get_convergence_curve()\\niter_index,rmse = tuple(zip(*conv_curve))\\n\\nplt.plot(iter_index,rmse, '-ok')\\nplt.xlabel('iteration')\\nplt.ylabel('RMSE')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_pipeline = Pipeline(\n",
    "    [('ratings_extractor', RatingsExtractor()),     \n",
    "     ('lf_recommender', LatentFactorRecSys(max_iter=10, tolerance=0.01))\n",
    "    ])\n",
    "\n",
    "\"\"\"num_samples = 1000\n",
    "rec_pipeline.fit(df_ratings.sample(num_samples, random_state=0))\n",
    "print (rec_pipeline)\n",
    "\n",
    "conv_curve = rec_pipeline.named_steps['lf_recommender'].get_convergence_curve()\n",
    "iter_index,rmse = tuple(zip(*conv_curve))\n",
    "\n",
    "plt.plot(iter_index,rmse, '-ok')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('RMSE')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "Next, we perform a gridsearch over our model parameters $f$ (number of latent factors), $\\lambda_{if}, \\lambda_{xf}, \\lambda_{ib}, \\lambda_{xb}$  and the hyperparameter $\\eta$ (learning rate). \n",
    "\n",
    "In the following grid search, I have used only 1,000 samples and $max\\_iter = 30$. In addition, all the reguralization coefficients are set to the same value to limit the search space. This is done to keep the computations tractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=2, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('ratings_extractor', RatingsExtractor()), ('lf_recommender', LatentFactorRecSys(learning_rate=0.001, max_iter=10, num_factors=20,\n",
      "          reg_item_bias=0.1, reg_item_fact=0.1, reg_user_bias=0.1,\n",
      "          reg_user_fact=0.1, tolerance=0.01))]),\n",
      "       fit_params={}, iid=True, n_jobs=3,\n",
      "       param_grid=[{'lf_recommender__num_factors': [40, 60, 80, 100], 'lf_recommender__learning_rate': [0.0001, 0.001, 0.01], 'lf_recommender__max_iter': [30], 'lf_recommender__reg_item_bias': [0.001], 'lf_recommender__reg_item_fact': [0.001], 'lf_recommender__reg_user_bias': [0.001], 'lf_recommender__reg_..._item_fact': [1.0], 'lf_recommender__reg_user_bias': [1.0], 'lf_recommender__reg_user_fact': [1.0]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "converged at iter = 2, rmse = 1.777826\n",
      "converged at iter = 2, rmse = 1.828849\n",
      "converged at iter = 2, rmse = 1.820899\n",
      "converged at iter = 2, rmse = 1.886549\n",
      "converged at iter = 2, rmse = 1.815157\n",
      "converged at iter = 2, rmse = 1.892730\n",
      "converged at iter = 2, rmse = 1.958522\n",
      "converged at iter = 2, rmse = 1.842210\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.495032\n",
      "converged at iter = 29, rmse = 1.465206\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.531471\n",
      "converged at iter = 30, rmse = 1.455406\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.502702\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.506124\n",
      "converged at iter = 30, rmse = 1.450238\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.447158\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.438726\n",
      "converged at iter = 27, rmse = 1.419675\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.443659\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.447455\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.462130\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.441478\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.435423\n",
      "converged at iter = 2, rmse = 1.784997\n",
      "converged at iter = 2, rmse = 1.893901\n",
      "converged at iter = 2, rmse = 1.874529\n",
      "converged at iter = 2, rmse = 1.833197\n",
      "converged at iter = 2, rmse = 1.837853\n",
      "converged at iter = 2, rmse = 1.898421\n",
      "converged at iter = 2, rmse = 1.826771\n",
      "converged at iter = 2, rmse = 1.874525\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.458926\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.498145\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.472105\n",
      "converged at iter = 27, rmse = 1.468265\n",
      "converged at iter = 27, rmse = 1.486684\n",
      "converged at iter = 30, rmse = 1.415607\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.484826\n",
      "converged at iter = 29, rmse = 1.453231\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.470400\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.469220\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.436152\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.457324\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.459726\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.438211\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.440269\n",
      "converged at iter = 2, rmse = 1.888414\n",
      "converged at iter = 2, rmse = 1.830839\n",
      "converged at iter = 2, rmse = 1.809775\n",
      "converged at iter = 2, rmse = 1.950127\n",
      "converged at iter = 2, rmse = 1.879681\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.443645\n",
      "converged at iter = 2, rmse = 1.811025\n",
      "converged at iter = 2, rmse = 1.759191\n",
      "converged at iter = 2, rmse = 1.803322\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.450282\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.431791\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.521118\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.517283\n",
      "converged at iter = 24, rmse = 1.440038\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.474165\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.478043\n",
      "converged at iter = 26, rmse = 1.422170\n",
      "converged at iter = 30, rmse = 1.463759\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.478135\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.465071\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.470699\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.455117\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.472355\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.471608\n",
      "converged at iter = 2, rmse = 1.823752\n",
      "converged at iter = 2, rmse = 1.849292\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.474583\n",
      "converged at iter = 2, rmse = 1.891493\n",
      "converged at iter = 2, rmse = 1.889316\n",
      "converged at iter = 2, rmse = 1.846779\n",
      "converged at iter = 2, rmse = 1.813008\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.459500\n",
      "converged at iter = 2, rmse = 1.906590\n",
      "converged at iter = 2, rmse = 1.865887\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.365381\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.353588\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.407780\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.354890\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.395890\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.380766\n",
      "converged at iter = 24, rmse = 0.681698\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.418345\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 1.364138\n",
      "converged at iter = 24, rmse = 0.676327\n",
      "converged at iter = 23, rmse = 0.660403\n",
      "converged at iter = 24, rmse = 0.698259\n",
      "converged at iter = 24, rmse = 0.690734\n",
      "converged at iter = 25, rmse = 0.672983\n",
      "converged at iter = 25, rmse = 0.675286\n",
      "converged at iter = 25, rmse = 0.662770\n",
      "not converged, number of iterations exceeded max_iter = 30 \n",
      "current rmse = 0.456928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('ratings_extractor', RatingsExtractor()), ('lf_recommender', LatentFactorRecSys(learning_rate=0.001, max_iter=10, num_factors=20,\n",
       "          reg_item_bias=0.1, reg_item_fact=0.1, reg_user_bias=0.1,\n",
       "          reg_user_fact=0.1, tolerance=0.01))]),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid=[{'lf_recommender__num_factors': [40, 60, 80, 100], 'lf_recommender__learning_rate': [0.0001, 0.001, 0.01], 'lf_recommender__max_iter': [30], 'lf_recommender__reg_item_bias': [0.001], 'lf_recommender__reg_item_fact': [0.001], 'lf_recommender__reg_user_bias': [0.001], 'lf_recommender__reg_..._item_fact': [1.0], 'lf_recommender__reg_user_bias': [1.0], 'lf_recommender__reg_user_fact': [1.0]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_latent_factors = [10] #[10, 20]\n",
    "regularizations = [0.1] #[0.1, 1.0]\n",
    "learning_rates = [0.01] #[0.01, 0.1]\n",
    "iterations = [2] #[25, 50, 75, 100]\"\"\"\n",
    "\n",
    "num_latent_factors = [40, 60, 80, 100]\n",
    "regularizations = [0.001, 0.01, 0.1, 1.0]\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "iterations = [30]\n",
    "\n",
    "grid= []\n",
    "for reg in regularizations:\n",
    "    grid.append({'lf_recommender__num_factors': num_latent_factors,\n",
    "                 'lf_recommender__learning_rate': learning_rates,\n",
    "                 'lf_recommender__max_iter': iterations,\n",
    "                 'lf_recommender__reg_item_bias': [reg],\n",
    "                 'lf_recommender__reg_item_fact': [reg],\n",
    "                 'lf_recommender__reg_user_bias': [reg],\n",
    "                 'lf_recommender__reg_user_fact': [reg],\n",
    "                })\n",
    "    \n",
    "#print (list(ParameterGrid(grid)))\n",
    "\n",
    "grid_search = GridSearchCV(rec_pipeline, param_grid=grid, \n",
    "                           cv=2, verbose=0, n_jobs=3)\n",
    "print (grid_search)\n",
    "\n",
    "num_samples = 1000\n",
    "grid_search.fit(df_ratings.sample(num_samples, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.18,  0.25,  0.29,  0.3 ,  3.88,  4.25,  3.7 ,  4.09,  4.3 ,\n",
       "         4.02,  4.03,  4.04,  0.3 ,  0.28,  0.3 ,  0.23,  3.99,  3.71,\n",
       "         3.81,  3.87,  3.84,  4.04,  4.54,  4.55,  0.24,  0.33,  0.35,\n",
       "         0.36,  4.02,  3.27,  4.11,  3.54,  3.61,  3.92,  4.  ,  4.12,\n",
       "         0.31,  0.32,  0.29,  0.32,  4.1 ,  4.01,  3.93,  4.07,  3.1 ,\n",
       "         3.1 ,  2.96,  2.54]),\n",
       " 'mean_score_time': array([ 0.01,  0.01,  0.01,  0.01,  0.02,  0.01,  0.01,  0.01,  0.02,\n",
       "         0.01,  0.02,  0.01,  0.02,  0.02,  0.01,  0.01,  0.03,  0.01,\n",
       "         0.01,  0.04,  0.02,  0.01,  0.02,  0.02,  0.01,  0.03,  0.02,\n",
       "         0.03,  0.01,  0.01,  0.02,  0.02,  0.02,  0.01,  0.02,  0.02,\n",
       "         0.02,  0.01,  0.02,  0.01,  0.01,  0.02,  0.01,  0.01,  0.01,\n",
       "         0.01,  0.03,  0.02]),\n",
       " 'mean_test_score': array([-1.76, -1.91, -1.91, -2.06, -0.84, -0.95, -0.87, -0.74,  0.83,\n",
       "         0.83,  0.83,  0.83, -1.87, -1.91, -1.84, -2.01, -0.87, -0.85,\n",
       "        -0.78, -0.81,  0.83,  0.82,  0.84,  0.83, -1.93, -2.  , -1.88,\n",
       "        -1.69, -0.85, -0.85, -0.85, -0.76,  0.81,  0.82,  0.81,  0.82,\n",
       "        -1.86, -2.03, -1.84, -2.01, -0.63, -0.6 , -0.58, -0.64,  0.61,\n",
       "         0.61,  0.61,  0.62]),\n",
       " 'mean_train_score': array([-1.76, -1.91, -1.91, -2.06, -0.84, -0.95, -0.87, -0.74,  0.83,\n",
       "         0.83,  0.83,  0.83, -1.87, -1.91, -1.84, -2.01, -0.87, -0.85,\n",
       "        -0.78, -0.81,  0.83,  0.82,  0.84,  0.83, -1.93, -2.  , -1.88,\n",
       "        -1.69, -0.85, -0.85, -0.85, -0.76,  0.81,  0.82,  0.81,  0.82,\n",
       "        -1.86, -2.03, -1.84, -2.01, -0.63, -0.6 , -0.58, -0.64,  0.61,\n",
       "         0.61,  0.61,  0.62]),\n",
       " 'param_lf_recommender__learning_rate': masked_array(data = [0.0001 0.0001 0.0001 0.0001 0.001 0.001 0.001 0.001 0.01 0.01 0.01 0.01\n",
       "  0.0001 0.0001 0.0001 0.0001 0.001 0.001 0.001 0.001 0.01 0.01 0.01 0.01\n",
       "  0.0001 0.0001 0.0001 0.0001 0.001 0.001 0.001 0.001 0.01 0.01 0.01 0.01\n",
       "  0.0001 0.0001 0.0001 0.0001 0.001 0.001 0.001 0.001 0.01 0.01 0.01 0.01],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lf_recommender__max_iter': masked_array(data = [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
       "  30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lf_recommender__num_factors': masked_array(data = [40 60 80 100 40 60 80 100 40 60 80 100 40 60 80 100 40 60 80 100 40 60 80\n",
       "  100 40 60 80 100 40 60 80 100 40 60 80 100 40 60 80 100 40 60 80 100 40 60\n",
       "  80 100],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lf_recommender__reg_item_bias': masked_array(data = [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
       "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
       "  1.0 1.0 1.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lf_recommender__reg_item_fact': masked_array(data = [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
       "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
       "  1.0 1.0 1.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lf_recommender__reg_user_bias': masked_array(data = [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
       "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
       "  1.0 1.0 1.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lf_recommender__reg_user_fact': masked_array(data = [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
       "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.1 0.1 0.1\n",
       "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
       "  1.0 1.0 1.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.001,\n",
       "   'lf_recommender__reg_item_fact': 0.001,\n",
       "   'lf_recommender__reg_user_bias': 0.001,\n",
       "   'lf_recommender__reg_user_fact': 0.001},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.01,\n",
       "   'lf_recommender__reg_item_fact': 0.01,\n",
       "   'lf_recommender__reg_user_bias': 0.01,\n",
       "   'lf_recommender__reg_user_fact': 0.01},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 0.1,\n",
       "   'lf_recommender__reg_item_fact': 0.1,\n",
       "   'lf_recommender__reg_user_bias': 0.1,\n",
       "   'lf_recommender__reg_user_fact': 0.1},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.0001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.001,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 40,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 60,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 80,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0},\n",
       "  {'lf_recommender__learning_rate': 0.01,\n",
       "   'lf_recommender__max_iter': 30,\n",
       "   'lf_recommender__num_factors': 100,\n",
       "   'lf_recommender__reg_item_bias': 1.0,\n",
       "   'lf_recommender__reg_item_fact': 1.0,\n",
       "   'lf_recommender__reg_user_bias': 1.0,\n",
       "   'lf_recommender__reg_user_fact': 1.0}),\n",
       " 'rank_test_score': array([34, 41, 42, 48, 25, 32, 30, 21,  3,  2,  5,  6, 38, 40, 36, 46, 31,\n",
       "        28, 23, 24,  7,  8,  1,  4, 43, 44, 39, 33, 27, 29, 26, 22, 11,  9,\n",
       "        12, 10, 37, 47, 35, 45, 19, 18, 17, 20, 14, 15, 16, 13], dtype=int32),\n",
       " 'split0_test_score': array([-1.65, -1.78, -1.76, -2.22, -0.87, -0.97, -0.8 , -0.76,  0.83,\n",
       "         0.84,  0.82,  0.84, -1.67, -1.95, -1.83, -2.02, -0.88, -0.81,\n",
       "        -0.68, -0.77,  0.82,  0.82,  0.84,  0.83, -1.99, -1.75, -1.96,\n",
       "        -1.73, -0.94, -0.93, -0.82, -0.7 ,  0.81,  0.81,  0.81,  0.81,\n",
       "        -1.79, -2.  , -1.76, -2.05, -0.56, -0.54, -0.54, -0.56,  0.61,\n",
       "         0.59,  0.6 ,  0.62]),\n",
       " 'split0_train_score': array([-1.65, -1.78, -1.76, -2.22, -0.87, -0.97, -0.8 , -0.76,  0.83,\n",
       "         0.84,  0.82,  0.84, -1.67, -1.95, -1.83, -2.02, -0.88, -0.81,\n",
       "        -0.68, -0.77,  0.82,  0.82,  0.84,  0.83, -1.99, -1.75, -1.96,\n",
       "        -1.73, -0.94, -0.93, -0.82, -0.7 ,  0.81,  0.81,  0.81,  0.81,\n",
       "        -1.79, -2.  , -1.76, -2.05, -0.56, -0.54, -0.54, -0.56,  0.61,\n",
       "         0.59,  0.6 ,  0.62]),\n",
       " 'split1_test_score': array([-1.86, -2.04, -2.06, -1.9 , -0.81, -0.94, -0.93, -0.72,  0.83,\n",
       "         0.83,  0.84,  0.82, -2.07, -1.87, -1.85, -2.  , -0.85, -0.89,\n",
       "        -0.89, -0.85,  0.84,  0.82,  0.83,  0.83, -1.87, -2.25, -1.8 ,\n",
       "        -1.65, -0.75, -0.77, -0.87, -0.83,  0.82,  0.82,  0.81,  0.82,\n",
       "        -1.92, -2.05, -1.92, -1.98, -0.69, -0.67, -0.63, -0.72,  0.61,\n",
       "         0.63,  0.61,  0.62]),\n",
       " 'split1_train_score': array([-1.86, -2.04, -2.06, -1.9 , -0.81, -0.94, -0.93, -0.72,  0.83,\n",
       "         0.83,  0.84,  0.82, -2.07, -1.87, -1.85, -2.  , -0.85, -0.89,\n",
       "        -0.89, -0.85,  0.84,  0.82,  0.83,  0.83, -1.87, -2.25, -1.8 ,\n",
       "        -1.65, -0.75, -0.77, -0.87, -0.83,  0.82,  0.82,  0.81,  0.82,\n",
       "        -1.92, -2.05, -1.92, -1.98, -0.69, -0.67, -0.63, -0.72,  0.61,\n",
       "         0.63,  0.61,  0.62]),\n",
       " 'std_fit_time': array([ 0.02,  0.  ,  0.04,  0.02,  0.34,  0.12,  0.08,  0.06,  0.  ,\n",
       "         0.  ,  0.05,  0.15,  0.04,  0.02,  0.04,  0.05,  0.07,  0.11,\n",
       "         0.1 ,  0.05,  0.04,  0.13,  0.02,  0.15,  0.04,  0.03,  0.01,\n",
       "         0.05,  0.18,  0.7 ,  0.05,  0.42,  0.03,  0.2 ,  0.06,  0.09,\n",
       "         0.  ,  0.01,  0.03,  0.03,  0.12,  0.19,  0.12,  0.03,  0.3 ,\n",
       "         0.04,  0.11,  0.68]),\n",
       " 'std_score_time': array([ 0.01,  0.  ,  0.  ,  0.  ,  0.01,  0.01,  0.  ,  0.  ,  0.01,\n",
       "         0.01,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.01,  0.  ,  0.  ,  0.01,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.01,  0.01,  0.  ,  0.  ,  0.01,  0.  ,  0.  ,\n",
       "         0.  ,  0.01,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.01,  0.  ,\n",
       "         0.  ,  0.01,  0.  ]),\n",
       " 'std_test_score': array([ 0.11,  0.13,  0.15,  0.16,  0.03,  0.01,  0.07,  0.02,  0.  ,\n",
       "         0.  ,  0.01,  0.01,  0.2 ,  0.04,  0.01,  0.01,  0.01,  0.04,\n",
       "         0.1 ,  0.04,  0.01,  0.  ,  0.  ,  0.  ,  0.06,  0.25,  0.08,\n",
       "         0.04,  0.09,  0.08,  0.02,  0.07,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.07,  0.03,  0.08,  0.04,  0.07,  0.07,  0.05,  0.08,  0.  ,\n",
       "         0.02,  0.01,  0.  ]),\n",
       " 'std_train_score': array([ 0.11,  0.13,  0.15,  0.16,  0.03,  0.01,  0.07,  0.02,  0.  ,\n",
       "         0.  ,  0.01,  0.01,  0.2 ,  0.04,  0.01,  0.01,  0.01,  0.04,\n",
       "         0.1 ,  0.04,  0.01,  0.  ,  0.  ,  0.  ,  0.06,  0.25,  0.08,\n",
       "         0.04,  0.09,  0.08,  0.02,  0.07,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.07,  0.03,  0.08,  0.04,  0.07,  0.07,  0.05,  0.08,  0.  ,\n",
       "         0.02,  0.01,  0.  ])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain optimal model on test set\n",
    "Next, we retrain the best estimator (estimator with optimal parameters) found by our grid search. Here, we increase $max\\_iter$ to 100 and decrease the convergence tolerance of our SGD to 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ratings_extractor', RatingsExtractor()), ('lf_recommender', LatentFactorRecSys(learning_rate=0.01, max_iter=100, num_factors=80,\n",
       "          reg_item_bias=0.01, reg_item_fact=0.01, reg_user_bias=0.01,\n",
       "          reg_user_fact=0.01, tolerance=0.001))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_\n",
    "#grid_search.best_estimator_.get_params()\n",
    "grid_search.best_estimator_.set_params(lf_recommender__max_iter=100)\n",
    "grid_search.best_estimator_.set_params(lf_recommender__tolerance=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('ratings_extractor', RatingsExtractor()), ('lf_recommender', LatentFactorRecSys(learning_rate=0.01, max_iter=100, num_factors=80,\n",
      "          reg_item_bias=0.01, reg_item_fact=0.01, reg_user_bias=0.01,\n",
      "          reg_user_fact=0.01, tolerance=0.001))])\n",
      "Retraining optimal model ...\n",
      "converged at iter = 77, rmse = 0.142825\n",
      "done in 397.656s.\n"
     ]
    }
   ],
   "source": [
    "rec = grid_search.best_estimator_\n",
    "print (rec)\n",
    "\n",
    "df_train, df_test = train_test_split_df(df_ratings, test_size=10)\n",
    "\n",
    "print ('Retraining optimal model ...')\n",
    "t0 = time()\n",
    "rec.fit_transform(df_train)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fb36a66f438>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgDAYghvAAAs5v8BSnFvqcxAYWcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb364d3f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#conv_curve = rec.steps[1][1].get_convergence_curve()\n",
    "conv_curve = rec.named_steps['lf_recommender'].get_convergence_curve()\n",
    "iter_index,rmse = tuple(zip(*conv_curve))\n",
    "\n",
    "plt.plot(iter_index,rmse, '-ok')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE on test set\n",
    "Next, we calculate the root mean square error (RMSE) on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ratings_extractor = RatingsExtractor()\\ntest_ratings_matrix = ratings_extractor.transform(df_test)\\nrow_col_indices = ratings_extractor.get_row_col_indices(df_test)\\ntest_ratings = [test_ratings_matrix[r,c] for r,c in row_col_indices]\\n\\npred = rec.named_steps['lf_recommender'].predict(row_col_indices)\\n\\nrmse = np.sqrt(mean_squared_error(test_ratings, pred))\\nprint (rmse)\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ratings_extractor = RatingsExtractor()\n",
    "test_ratings_matrix = ratings_extractor.transform(df_test)\n",
    "row_col_indices = ratings_extractor.get_row_col_indices(df_test)\n",
    "test_ratings = [test_ratings_matrix[r,c] for r,c in row_col_indices]\n",
    "\n",
    "pred = rec.named_steps['lf_recommender'].predict(row_col_indices)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, pred))\n",
    "print (rmse)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ratings = df_test['rating'].values\n",
    "itemid_userid_array = [tuple(x) for x in df_test[['itemId', 'userId']]\n",
    "                       .to_records(index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lf_recommender': LatentFactorRecSys(learning_rate=0.001, max_iter=10, num_factors=20,\n",
       "           reg_item_bias=0.1, reg_item_fact=0.1, reg_user_bias=0.1,\n",
       "           reg_user_fact=0.1, tolerance=0.01),\n",
       " 'ratings_extractor': RatingsExtractor()}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968712576811\n"
     ]
    }
   ],
   "source": [
    "lf_recommender = rec.named_steps['lf_recommender']\n",
    "ratings_extractor = rec.named_steps['ratings_extractor']\n",
    "#ratings_extractor = RatingsExtractor()\n",
    "#ratings_extractor.transform(df_ratings)\n",
    "pred = lf_recommender.predict(itemid_userid_array, ratings_extractor)\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, pred))\n",
    "print (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **RMSE of 0.97** looks pretty good, given that we didn't perform exhaustive search for the best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "with open('lf_movie_recommender.pkl', 'wb') as handle:\n",
    "    pickle.dump(rec, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load trained model\n",
    "#with open('lf_movie_recommender.pkl', 'rb') as handle:\n",
    "#    rec = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions: Filter similar movies based on cosine distance as a similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.9 ,  0.89, ...,  0.71,  0.69,  0.83],\n",
       "       [ 0.9 ,  0.  ,  1.09, ...,  1.  ,  0.89,  0.99],\n",
       "       [ 0.89,  1.09,  0.  , ...,  0.92,  0.82,  0.89],\n",
       "       ..., \n",
       "       [ 0.71,  1.  ,  0.92, ...,  0.  ,  0.46,  0.36],\n",
       "       [ 0.69,  0.89,  0.82, ...,  0.46,  0.  ,  0.31],\n",
       "       [ 0.83,  0.99,  0.89, ...,  0.36,  0.31,  0.  ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine_similarity(item_factors):\n",
    "    cos_sim = np.matmul(item_factors, item_factors.transpose())\n",
    "    norm = np.diagonal(cos_sim)\n",
    "    norm_mat = np.sqrt(np.outer(norm, norm))\n",
    "    cos_sim = np.divide(cos_sim, norm_mat)\n",
    "    return cos_sim\n",
    "\n",
    "def cosine_distance(item_factors):\n",
    "    return 1 - cosine_similarity(item_factors)\n",
    "\n",
    "cos_dist = cosine_distance(lf_recommender.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"num_recs = 5       \\nitemid = 1\\nmovie_name = get_movie_name(df_movies, itemid)\\nprint ('%s ==>' %movie_name)\\nget_similar_items(itemid, num_recs)\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_movie_name(df_movies, itemid):\n",
    "    movie_name = df_movies[df_movies['movieId']==itemid]['title'].values[0]\n",
    "    return movie_name\n",
    "\n",
    "\n",
    "def get_similar_items(itemid, num_recs):\n",
    "    itemindex = ratings_extractor.item2index_dict[itemid]\n",
    "    dists = cos_dist[itemindex,:]\n",
    "    indices = dists.argsort()[1:num_recs+1]\n",
    "\n",
    "    similar_item_ids = [ratings_extractor.index2item_dict[i] for i in indices]\n",
    "        \n",
    "    similar_item_names = []\n",
    "    for itemid in similar_item_ids:\n",
    "        similar_item_names.append(get_movie_name(df_movies, itemid))\n",
    "        \n",
    "    return similar_item_names\n",
    "        \n",
    "    \n",
    "\"\"\"num_recs = 5       \n",
    "itemid = 1\n",
    "movie_name = get_movie_name(df_movies, itemid)\n",
    "print ('%s ==>' %movie_name)\n",
    "get_similar_items(itemid, num_recs)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions: Retrieve IMDB ID given a movie title\n",
    "IMDB ID is used to get movie poster from [themoviedb.org API](!https://www.themoviedb.org/documentation/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toy Story'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_year(movie_name):\n",
    "    movie_name = re.sub(r'\\([^)]*\\)', '', movie_name).strip()\n",
    "\n",
    "    return movie_name\n",
    "\n",
    "\n",
    "def imdb_id_from_title(title):\n",
    "    title = strip_year(title)\n",
    "    \n",
    "    pattern = 'http://www.imdb.com/xml/find?json=1&nr=1&tt=on&q={movie_title}'\n",
    "    url = pattern.format(movie_title=urllib.parse.quote_plus(title))\n",
    "    r = requests.get(url)\n",
    "    res = r.json()\n",
    "    # sections in descending order or preference\n",
    "    for section in ['popular','exact','substring']:\n",
    "        key = 'title_' + section \n",
    "        if key in res:\n",
    "            return res[key][0]['id']\n",
    "        \n",
    "        \n",
    "\"\"\"strip_year('Toy Story (1995)')\"\"\"\n",
    "\"\"\"imdb_id_from_title('Toy Story (1995)')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions: Display movie posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONFIG_PATTERN = 'http://api.themoviedb.org/3/configuration?api_key={key}'\n",
    "KEY = 'cd3fbcc9cb70affd9a68b0951b3d0997'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size_str_to_int(x):\n",
    "    return float(\"inf\") if x == 'original' else int(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = CONFIG_PATTERN.format(key=KEY)\n",
    "r = requests.get(url)\n",
    "config = r.json()\n",
    "\n",
    "base_url = config['images']['base_url']\n",
    "sizes = config['images']['poster_sizes']\n",
    "max_size = max(sizes, key=size_str_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"movie_name = 'Toy Story'    \\nget_poster(movie_name)\""
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_poster_url(movie_name):\n",
    "    imdb_id = imdb_id_from_title(movie_name)\n",
    "\n",
    "    IMG_PATTERN = 'http://api.themoviedb.org/3/movie/{imdbid}/images?api_key={key}' \n",
    "    r = requests.get(IMG_PATTERN.format(key=KEY,imdbid=imdb_id))\n",
    "    api_response = r.json()\n",
    "    \n",
    "    poster = api_response['posters'][0] # Get the best rated poster\n",
    "    rel_path = poster['file_path']\n",
    "    poster_url = \"{0}{1}{2}\".format(base_url, max_size, rel_path)\n",
    "    return poster_url\n",
    "\n",
    "\n",
    "\"\"\"movie_name = 'Toy Story'    \n",
    "get_poster(movie_name)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movieid = 1\\ndisplay_rec_movies(movieid)'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see https://stackoverflow.com/questions/19471814/display-multiple-images-in-one-ipython-notebook-cell\n",
    "def make_html(image_url):\n",
    "    return \"<img style='width: 120px; margin: 0px; float: left; \\\n",
    "    border: 1px solid black;' src='%s' />\" % image_url\n",
    "\n",
    "\n",
    "def display_rec_movies(movieid, num_recs):\n",
    "    movie_name = get_movie_name(df_movies, movieid)\n",
    "    poster_url = get_poster_url(movie_name)\n",
    "    \n",
    "    print ('Input movie:')\n",
    "    display(HTML(make_html(poster_url)))\n",
    "    \n",
    "    recommended_item_names = get_similar_items(movieid, num_recs)\n",
    "    \n",
    "    print ('Recommended movies: ')\n",
    "    imagesList = ''\n",
    "    for movie_name in recommended_item_names:\n",
    "        poster_url = get_poster_url(movie_name)\n",
    "        imagesList += make_html(poster_url)\n",
    "    display(HTML(imagesList))\n",
    "\n",
    "    \n",
    "\"\"\"movieid = 1\n",
    "display_rec_movies(movieid)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input movie:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/uMZqKhT4YA6mqo2yczoznv7IDmv.jpg' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/kuTPkbQmHxBHsxaKMUL1kUchhdE.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/cxcsBwMvrSdUDjx527YWwhZYRZX.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/ha3niQHexpnQgFgK8SNnrtpctv.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/AqYmOBxLjASrj5UtybIh7Axyv77.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/3D4XNaaBZcHajoA6hcaeu1NLWxf.jpg' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Input movie:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/trtANqAEy9dxRCeIe7YEDVeGkLw.jpg' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/2Kr5u2cvt0lKcIk1NyUrUs8eeDN.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/jABswtfPt03TWjfJnUJ3HmMWWjT.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/lFbBQ55MkBxVxQPwALjzMu3y9rD.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/qWjRfBwr4VculczswwojXgoU0mq.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/yGMnu5JddJXl87S9wmDGPAKF75W.jpg' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Input movie:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/jgJoRWltoS17nD5MAQ1yK2Ztefw.jpg' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/bXQIL36VQdzJ69lcjQR1WQzJqQR.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/vYzFGhcca17r9Yzfwc6osZoriMo.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/drtXi58nN6P3zcoLh6wUlsZAYqh.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/oahXApmG38L2rkopdyBZcA9ZxV0.jpg' /><img style='width: 120px; margin: 0px; float: left;     border: 1px solid black;' src='http://image.tmdb.org/t/p/original/ye1xEG6SnrfAvzAkgLQSVNIm1oI.jpg' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieids = [1, 10, 50]\n",
    "num_recs = 5       \n",
    "\n",
    "for movieid in movieids:\n",
    "    display_rec_movies(movieid, num_recs)\n",
    "    print ('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
