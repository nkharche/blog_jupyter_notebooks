{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercari Price Suggestion Challenge (Model development)\n",
    "This competition is hosted by [Mercari](!https://www.mercari.com/), Japanâ€™s biggest community-powered shopping app. They provide a hassle-free and secure way for anyone to buy and sell stuff straight from their mobile device.\n",
    "\n",
    "In this competition, we are asked to build an algorithm to predict the sale price of a product based on information a user provides for this product. The schema of the data is as follows:\n",
    " * train_id or test_id - the id of the listing\n",
    " * name - the title of the listing. Note that we have cleaned the data to remove text that look like prices (e.g. \\$20) to avoid leakage. These removed prices are represented as [rm]\n",
    " * item_condition_id - the condition of the items provided by the seller\n",
    "category_name - category of the listing\n",
    " * brand_name\n",
    " * price - the price that the item was sold for. This is the target variable that you will predict. The unit is USD. This column doesn't exist in test.tsv since that is what you will predict.\n",
    " * shipping - 1 if shipping fee is paid by seller and 0 by buyer\n",
    " * item_description - the full description of the item. Note that we have cleaned the data to remove text that look like prices (e.g. $20) to avoid leakage. These removed prices are represented as [rm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we develop a model to predict the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/train.tsv', sep='\\t')\n",
    "df = df.drop(['train_id'], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>969957</th>\n",
       "      <td>J.CREW Drawstring dress in pebble dot</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Dresses/Above Knee, Mini</td>\n",
       "      <td>J. Crew</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>J.CREW Drawstring dress in pebble dot SIZE : M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41192</th>\n",
       "      <td>Reserved</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Tools &amp; Accessories/Makeup Brushes &amp; Tools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>By Sigma 2 brushes Deluxe sigma mat and shampoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  item_condition_id  \\\n",
       "969957  J.CREW Drawstring dress in pebble dot                  1   \n",
       "41192                                Reserved                  1   \n",
       "\n",
       "                                            category_name brand_name  price  \\\n",
       "969957                     Women/Dresses/Above Knee, Mini    J. Crew   20.0   \n",
       "41192   Beauty/Tools & Accessories/Makeup Brushes & Tools        NaN   27.0   \n",
       "\n",
       "        shipping                                   item_description  \n",
       "969957         1  J.CREW Drawstring dress in pebble dot SIZE : M...  \n",
       "41192          0    By Sigma 2 brushes Deluxe sigma mat and shampoo  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will work with a samller subset for code development and test \n",
    "df = df.sample(n=None, frac=0.05)\n",
    "print (len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in training set: 74127\n",
      "\n",
      "Number of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name                     0\n",
       "item_condition_id        0\n",
       "category_name          291\n",
       "brand_name           31623\n",
       "price                    0\n",
       "shipping                 0\n",
       "item_description         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Total number of rows in training set: {:d}'.format(len(df)))\n",
    "\n",
    "print ('\\nNumber of missing values')\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values\n",
    " * A missing category name becomes 'Other'\n",
    " * A missing brand name becomes 'Unknown'\n",
    " * A missing item description becomes 'No description yet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MissingValuesHandler(BaseEstimator, TransformerMixin):\n",
    "    # Extracts a given list of columns from the input dataframe and returns a new dataframe\n",
    "    \n",
    "    def __init__(self, col_name_replacevalue_tuples):\n",
    "        self.col_name_replacevalue_tuples = col_name_replacevalue_tuples\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        for (col, val) in self.col_name_replacevalue_tuples:\n",
    "            df[col] = df[col].fillna(val)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_values_handler = MissingValuesHandler([('category_name', 'Other'), \n",
    "                                               ('brand_name', 'Unknown'), \n",
    "                                               ('item_description', 'No description yet')]\n",
    "                                             )\n",
    "df = missing_values_handler.fit_transform(df)#.iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnSelectTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Extracts a given list of columns from the input dataframe and returns a new dataframe\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return df[self.col_names].values\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.col_names\n",
    "    \n",
    "\n",
    "#ColumnSelectTransformer(['item_condition_id', 'brand_name', 'shipping']).fit_transform(df.iloc[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories\n",
    "Each item is hierarchically classified into 3 subcategories. For example 'Men/Sweats & Hoodies/Hoodie'. We convert subcategories into lists and use them as one-hot-encoded features in our predictive model. The main category is stored in a separate column called 'cat_1'. There are 11 unique main categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = r'\\b\\w+\\b'\n",
    "regex = r'[^-\\w]+'\n",
    "pattern_alphanumeric = re.compile('([^\\s\\w]|_)+')\n",
    "\n",
    "class CategoriesProcessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cat_col):\n",
    "        self.cat_col = cat_col\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df[self.cat_col] = df[self.cat_col].apply(lambda x: self.parse_categories_line(x))\n",
    "        df['cat_1'] = df[self.cat_col].apply(lambda x: x[0] if x else '')        \n",
    "        return df\n",
    "        \n",
    "    def parse_categories_line(self, line):\n",
    "        try:\n",
    "            cats = ' '.join(line.split('/')[:3]) \n",
    "            cats = re.sub('-','', line)\n",
    "            cats = cats.lower()\n",
    "                   # convert to lowercase\n",
    "            cats = pattern_alphanumeric.sub(' ', cats)\n",
    "                   # Remove everything except alphanumeric characters            \n",
    "            return cats\n",
    "        except:\n",
    "            return ['Other']\n",
    "\n",
    "#categories_processor = CategoriesProcessor('category_name').fit_transform(df).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<74127x834 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 292290 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipe = Pipeline([('categories_processor', CategoriesProcessor('category_name')),\n",
    "                     ('col_selctor', ColumnSelectTransformer('category_name')),                     \n",
    "                     ('CountVectorizer', CountVectorizer())\n",
    "                    ])\n",
    "cat_features = cat_pipe.fit_transform(df)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cat_pipe.named_steps['CountVectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Item description tf-idf\n",
    "Now we generate tf-idf features using 'item_description' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern_alphanumeric = re.compile('([^\\s\\w]|_)+')\n",
    "pattern_numeric = re.compile('[0-9]+')\n",
    "pattern_rem_multi_spaces = re.compile('\\s\\s+')\n",
    "pattern_words = re.compile(r'\\w*\\d\\w*')\n",
    "\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        result_df = df[self.columns[0]]\n",
    "        for col in self.columns[1:]:\n",
    "            result_df += \" \" + df[col]\n",
    "        result_df = result_df \\\n",
    "                    .apply(lambda x: self.string_cleanup(str(x)))\n",
    "        return result_df.values\n",
    "        \n",
    "    def string_cleanup(self, string):\n",
    "        string = string.strip()\n",
    "                # Remove leading and trailing whitespaces from EmployerName\n",
    "        string = string.lower()\n",
    "                # convert to lowercase\n",
    "        string = pattern_alphanumeric.sub(' ', string)\n",
    "                # Remove everything except alphanumeric characters\n",
    "        string = pattern_numeric.sub('', string).strip()\n",
    "                # Remove numbers\n",
    "        string = pattern_rem_multi_spaces.sub(' ', string)\n",
    "                # Replace multiple whitespaces by a single whitespace    \n",
    "        return string    \n",
    "    \n",
    "    \n",
    "#TextCleaner(['item_description', 'name']).fit_transform(df.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union([\"rm\"])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 25000, \n",
    "                                   ngram_range = (1,3),\n",
    "                                   stop_words = stop_words)\n",
    "\n",
    "description_pipe = Pipeline([('text_cleaner', TextCleaner(['item_description'])),\n",
    "                             ('vectorizer', tfidf_vectorizer)\n",
    "                            ])\n",
    "\n",
    "#description_features = description_pipe.fit_transform(df, y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name tf-idf\n",
    "Now we generate tf-idf features using 'name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union([\"rm\"])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 25000, \n",
    "                                   ngram_range = (1,3),\n",
    "                                   stop_words = stop_words)\n",
    "\n",
    "name_pipe = Pipeline([('text_cleaner', TextCleaner(['name'])),\n",
    "                      ('vectorizer', tfidf_vectorizer)\n",
    "                     ])\n",
    "\n",
    "#name_features = name_pipe.fit_transform(df, y=None)\n",
    "#name_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brand\n",
    "Encode 'brand' column to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand encoder\n"
     ]
    }
   ],
   "source": [
    "print(\"Brand encoder\")\n",
    "brand_pipe = Pipeline([('col_selctor', ColumnSelectTransformer('brand_name')),\n",
    "                       ('CountVectorizer', CountVectorizer(max_features=2500))    \n",
    "                      ])\n",
    "#brand_features = brand_pipe.fit_transform(df)\n",
    "#brand_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item_condition_id\n",
    "One-hot-encode 'item_condition_id' column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemCond_pipe = Pipeline([('col_selctor', ColumnSelectTransformer(['item_condition_id'])),\n",
    "                          ('vectorizer', OneHotEncoder())    \n",
    "                         ])\n",
    "#itemCond_features = itemCond_pipe.fit_transform(df)\n",
    "#itemCond_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score brands by price\n",
    "We calculate a score for each brand as follows: for each category-brand pair we calculate the ratio of median price of all items of that brand belonging to a category and median price of all items in that category. The final brand score is the average of these ratios over all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BrandScoreCalculator(BaseEstimator, TransformerMixin):\n",
    "    # Returns fuzzy match score between EmployerName and Description of the transaction\n",
    "    \n",
    "    def __init__(self, brand_col, cat_col, price_col, cutoff_count=10):\n",
    "        self.brand_col = brand_col\n",
    "        self.cat_col = cat_col\n",
    "        self.price_col = price_col \n",
    "        self.cutoff_count = cutoff_count\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        df_median_cat_price = df.groupby([self.cat_col])[self.price_col].agg(['median']).add_prefix('price_')\n",
    "        self.median_cat_price = {k: v[0] for k,v in df_median_cat_price.T.to_dict('list').items()}\n",
    "        \n",
    "        self.brand_counts = df.groupby(self.brand_col)[self.brand_col].agg(['count']).add_prefix('brand_') #.reset_index()\n",
    "        \n",
    "        self.brand_score = {k: 0 for k in df[self.brand_col].unique()}\n",
    "        gr = df.groupby([self.brand_col])\n",
    "        for k, v in gr:\n",
    "            df_temp = v.groupby([self.cat_col, self.brand_col])[self.price_col].agg(['median']).add_prefix('price_').reset_index()\n",
    "            df_temp['cat_price_ratio'] = df_temp[[self.cat_col, self.brand_col, 'price_median']] \\\n",
    "                                         .apply(lambda x: self.cat_price_ratio(x[self.cat_col], x[self.brand_col], x['price_median']), axis=1)\n",
    "            self.brand_score[k] = df_temp['cat_price_ratio'].mean()\n",
    "\n",
    "        self.df_brand_score = pd.DataFrame(list(self.brand_score.items()), columns=['brand', 'brand_score'])        \n",
    "        return self\n",
    "    \n",
    "     \n",
    "    def transform(self, df):\n",
    "        return df[self.brand_col].apply(lambda x: self.get_price_ratio(x))\n",
    "        \n",
    "    def cat_price_ratio(self, cat, brand, price):\n",
    "        if price==0 or self.brand_counts.loc[brand].values<self.cutoff_count:\n",
    "            return 1.0\n",
    "        return price/self.median_cat_price[cat]\n",
    "\n",
    "    def get_price_ratio(self, brand):\n",
    "        try:\n",
    "            return self.brand_score[brand]\n",
    "        except KeyError:\n",
    "            return 1.0\n",
    "        \n",
    "    def get_brand_scores(self):\n",
    "        return self.df_brand_score.sort_values(by='brand_score', ascending=False)\n",
    "    \n",
    "    \n",
    "#brand_score_calculator = BrandScoreCalculator('brand_name', 'cat_1', 'price', cutoff_count = 10)\n",
    "#brand_score_calculator.fit(df, None)\n",
    "#brand_score_calculator.transform(df.iloc[:10])\n",
    "#brand_score_calculator.get_brand_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert 1D numpy array to 2D numpy array with one column.\n",
    "reshaper = FunctionTransformer(lambda X: X.values.reshape(-1,1),validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brand_score_pipe = Pipeline([('brand_score_calculator', BrandScoreCalculator('brand_name', 'cat_1', 'price', cutoff_count = 10)),\n",
    "                            ('reshaper', reshaper),\n",
    "                            #('poly', PolynomialFeatures(2))\n",
    "                           ])\n",
    "brand_score_features = brand_score_pipe.fit_transform(df)\n",
    "#brand_score_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature union\n",
    "Combine all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_union = FeatureUnion([\n",
    "    ('itemCond_features', itemCond_pipe),\n",
    "    ('shipping_features', ColumnSelectTransformer(['shipping'])),\n",
    "    ('cat_features', cat_pipe),\n",
    "    ('brand_features', brand_pipe),\n",
    "    ('brand_score_features', brand_score_pipe),\n",
    "    ('description_features', description_pipe),\n",
    "    ('name_features', name_pipe)\n",
    "])\n",
    "\n",
    "#features = feature_union.fit_transform(df)\n",
    "#print (features.shape)\n",
    "#features\n",
    "#print ('Alleatures done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regression model.\n"
     ]
    }
   ],
   "source": [
    "print ('Training regression model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59079 15048\n"
     ]
    }
   ],
   "source": [
    "def df_train_test_split(df, y_col_name, test_fraction=0.2):\n",
    "    # Splits input dataframe into train and test dataframes.\n",
    "    # Response variables y_train and y_test are returned as numpy array\n",
    "    \n",
    "    msk = np.random.rand(len(df)) < 1-test_fraction\n",
    "    df_train = df[msk]\n",
    "    df_test = df[~msk]\n",
    "    y_train = df_train[y_col_name].values\n",
    "    y_test = df_test[y_col_name].values\n",
    "    return df_train, df_test, y_train, y_test\n",
    "\n",
    "df_train, df_test, y_train, y_test \\\n",
    "    = df_train_test_split(df, 'price', test_fraction=0.2)\n",
    "print (len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('missing_values_handler', MissingValuesHandler(col_name_replacevalue_tuples=[('category_name', 'Other'), ('brand_name', 'Unknown'), ('item_description', 'No description yet')])), ('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('itemCond_features', Pipeline(memory=None,\n",
       "     ste...it_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    ('missing_values_handler', missing_values_handler),\n",
    "    ('features', feature_union),\n",
    "    ('reg', model)\n",
    "])\n",
    "\n",
    "reg_pipe.fit(df_train, np.log(y_train+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean squared error = 508.22, train r2_score = 0.64\n",
      "Train mean squared log error = 0.13\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.exp(reg_pipe.predict(df_train)) - 1\n",
    "print ('Train mean squared error = {:.2f}, train r2_score = {:.2f}'.format(mean_squared_error(y_train, y_train_pred), r2_score(y_train, y_train_pred)))\n",
    "print ('Train mean squared log error = {:.2f}'.format(mean_squared_log_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean squared error = 791.15, test r2_score = 0.40\n",
      "Test mean squared log error = 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkharche/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.exp(reg_pipe.predict(df_test)) - 1\n",
    "print ('Test mean squared error = {:.2f}, test r2_score = {:.2f}'.format(mean_squared_error(y_test, y_test_pred), r2_score(y_test, y_test_pred)))\n",
    "print ('Test mean squared log error = {:.2f}'.format(mean_squared_log_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kaggle test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_kaggle_test = pd.read_csv('../input/test.tsv', sep='\\t')\n",
    "df_kaggle_test = df_kaggle_test.drop(['test_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_kaggle_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_kaggle_test_pred = np.exp(reg_pipe.predict(df_kaggle_test)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(y_kaggle_test_pred, columns=['price'])\n",
    "submit_df.index.name = 'test_id'\n",
    "submit_df.to_csv('mercari_submission_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
